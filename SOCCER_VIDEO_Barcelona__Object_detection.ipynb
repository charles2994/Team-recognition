{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charles2994/Team-recognition/blob/main/SOCCER_VIDEO_Barcelona__Object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF362NBKMnxz",
        "outputId": "b5e7c22d-91ba-475a-c6ca-68043475e4cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.4.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 27.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.47.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.19.4)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.12)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.26.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.1\n",
            "    Uninstalling tensorflow-2.9.1:\n",
            "      Successfully uninstalled tensorflow-2.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-models-official 2.9.2 requires tensorflow~=2.9.0, but you have tensorflow 2.8.0+zzzcolab20220506162203 which is incompatible.\n",
            "tensorflow-text 2.9.0 requires tensorflow<2.10,>=2.9.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.0+zzzcolab20220506162203 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.8.0 tensorboard-2.8.0 tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 47 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 10s (42.2 MB/s)\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155631 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grHzJ_QAdYci"
      },
      "source": [
        "Clone TENSORFLOW github repository "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "51xE0fGQcIco"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgcsmXn7dwrv"
      },
      "source": [
        "From cloned repository install tensorflow object APIs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0bRX4HAjdnst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526b658a-a9da-46d4-bd3f-6e4d17bfa736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research/deploy/models/research\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.40.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.2)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.17.1)\n",
            "Requirement already satisfied: tensorflow-text~=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
            "Collecting tensorflow~=2.9.0\n",
            "  Using cached tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.28.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Collecting keras\n",
            "  Using cached keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.47.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.3)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: cloudpickle<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.7)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.20.6)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.5.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.9.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.8.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694828 sha256=4bff2b3c758f115bd9c9ac101f059cc556d4decae1a726be6e41f0bce3978a82\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0j8lrn9i/wheels/7b/3d/1d/ea395a24f62b66f8592a759624e3cd0d94c9ac3160134a840e\n",
            "Successfully built object-detection\n",
            "Installing collected packages: tensorboard, keras, tensorflow, object-detection\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed keras-2.9.0 object-detection-0.1 tensorboard-2.9.1 tensorflow-2.9.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
          ]
        }
      ],
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Uz7vHD0K_k"
      },
      "source": [
        "Import Packages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "S3Dzai2q0G4s"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC3snf7F0O1l",
        "outputId": "5e6088b9-8eaa-4046-c98b-7ad817411c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-15 01:27:31.017365: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "W0715 01:27:31.753538 139991156664192 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.27s\n",
            "I0715 01:27:32.290398 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.27s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.53s\n",
            "I0715 01:27:33.821126 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.53s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.7s\n",
            "I0715 01:27:34.521281 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.7s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.74s\n",
            "I0715 01:27:35.262638 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.74s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 5.16s\n",
            "I0715 01:27:40.419506 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 5.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.01s\n",
            "I0715 01:27:40.431390 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.11s\n",
            "I0715 01:27:40.542642 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "I0715 01:27:40.573939 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.06s\n",
            "I0715 01:27:40.634429 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.49s\n",
            "I0715 01:27:41.124435 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.49s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.43s\n",
            "I0715 01:27:41.558929 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.43s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.56s\n",
            "I0715 01:27:42.114867 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.56s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.32s\n",
            "I0715 01:27:42.432365 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.39s\n",
            "I0715 01:27:42.819238 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.39s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.17s\n",
            "I0715 01:27:42.995089 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0715 01:27:43.677423 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0715 01:27:43.677733 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0715 01:27:43.677898 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0715 01:27:43.682622 139991156664192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0715 01:27:43.738958 139991156664192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0715 01:27:43.739253 139991156664192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0715 01:27:44.098775 139991156664192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0715 01:27:44.101652 139991156664192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0715 01:27:45.217774 139991156664192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0715 01:27:45.218073 139991156664192 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0715 01:27:46.582644 139991156664192 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0715 01:27:46.582977 139991156664192 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0715 01:27:47.514851 139991156664192 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0715 01:27:47.515465 139991156664192 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0715 01:27:48.605295 139991156664192 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0715 01:27:48.605564 139991156664192 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0715 01:27:49.530921 139991156664192 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0715 01:27:49.531207 139991156664192 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0715 01:27:49.789253 139991156664192 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0715 01:27:49.940086 139991156664192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0715 01:27:50.060144 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0715 01:27:50.060412 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0715 01:27:50.060519 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0715 01:27:50.063727 139991156664192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0715 01:27:50.095580 139991156664192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0715 01:27:50.095847 139991156664192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0715 01:27:50.789453 139991156664192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0715 01:27:50.789772 139991156664192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0715 01:27:51.623123 139991156664192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0715 01:27:51.623437 139991156664192 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0715 01:27:52.415063 139991156664192 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0715 01:27:52.415380 139991156664192 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0715 01:27:52.998662 139991156664192 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0715 01:27:52.998896 139991156664192 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0715 01:27:53.463763 139991156664192 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0715 01:27:53.463987 139991156664192 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0715 01:27:54.116354 139991156664192 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0715 01:27:54.116598 139991156664192 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0715 01:27:54.399779 139991156664192 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0715 01:27:54.471690 139991156664192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0715 01:27:54.551699 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0715 01:27:54.551928 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0715 01:27:54.552021 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0715 01:27:54.554097 139991156664192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0715 01:27:54.578780 139991156664192 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0715 01:27:54.579046 139991156664192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0715 01:27:54.774143 139991156664192 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0715 01:27:54.774367 139991156664192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0715 01:27:55.105153 139991156664192 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0715 01:27:55.105375 139991156664192 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0715 01:27:55.438946 139991156664192 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0715 01:27:55.439165 139991156664192 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0715 01:27:55.905943 139991156664192 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0715 01:27:55.906170 139991156664192 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0715 01:27:56.381417 139991156664192 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0715 01:27:56.381627 139991156664192 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0715 01:27:57.051697 139991156664192 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0715 01:27:57.051934 139991156664192 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0715 01:27:57.353628 139991156664192 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0715 01:27:57.428804 139991156664192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0715 01:27:57.502965 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0715 01:27:57.503190 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0715 01:27:57.503275 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0715 01:27:57.505412 139991156664192 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0715 01:27:57.528387 139991156664192 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0715 01:27:57.528596 139991156664192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0715 01:27:57.709567 139991156664192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0715 01:27:57.709852 139991156664192 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0715 01:27:58.298225 139991156664192 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0715 01:27:58.298481 139991156664192 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0715 01:27:58.631235 139991156664192 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0715 01:27:58.631462 139991156664192 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0715 01:27:59.215266 139991156664192 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0715 01:27:59.215493 139991156664192 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0715 01:27:59.823338 139991156664192 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0715 01:27:59.823563 139991156664192 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0715 01:28:00.602730 139991156664192 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0715 01:28:00.602984 139991156664192 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0715 01:28:00.953279 139991156664192 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0715 01:28:01.039463 139991156664192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0715 01:28:01.120667 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0715 01:28:01.120904 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0715 01:28:01.121003 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0715 01:28:01.123020 139991156664192 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0715 01:28:01.144549 139991156664192 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0715 01:28:01.144774 139991156664192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0715 01:28:01.322483 139991156664192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0715 01:28:01.322701 139991156664192 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0715 01:28:01.758041 139991156664192 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0715 01:28:01.758264 139991156664192 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0715 01:28:02.201585 139991156664192 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0715 01:28:02.201819 139991156664192 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0715 01:28:02.897199 139991156664192 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0715 01:28:02.897432 139991156664192 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0715 01:28:03.604109 139991156664192 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0715 01:28:03.604329 139991156664192 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0715 01:28:04.731776 139991156664192 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0715 01:28:04.732005 139991156664192 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0715 01:28:05.089530 139991156664192 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0715 01:28:05.169078 139991156664192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0715 01:28:05.265314 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0715 01:28:05.265541 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0715 01:28:05.265650 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0715 01:28:05.267786 139991156664192 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0715 01:28:05.289608 139991156664192 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0715 01:28:05.289820 139991156664192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0715 01:28:05.548566 139991156664192 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0715 01:28:05.548790 139991156664192 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0715 01:28:06.100562 139991156664192 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0715 01:28:06.101022 139991156664192 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0715 01:28:06.928771 139991156664192 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0715 01:28:06.929058 139991156664192 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0715 01:28:07.750132 139991156664192 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0715 01:28:07.750358 139991156664192 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0715 01:28:08.623994 139991156664192 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0715 01:28:08.624201 139991156664192 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0715 01:28:09.983573 139991156664192 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0715 01:28:09.983840 139991156664192 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0715 01:28:10.845340 139991156664192 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0715 01:28:10.989819 139991156664192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0715 01:28:11.237540 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0715 01:28:11.237815 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0715 01:28:11.237941 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0715 01:28:11.240962 139991156664192 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0715 01:28:11.275787 139991156664192 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0715 01:28:11.276039 139991156664192 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0715 01:28:11.702757 139991156664192 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0715 01:28:11.702990 139991156664192 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0715 01:28:12.367511 139991156664192 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0715 01:28:12.367734 139991156664192 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0715 01:28:13.025032 139991156664192 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0715 01:28:13.025234 139991156664192 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0715 01:28:14.002477 139991156664192 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0715 01:28:14.002713 139991156664192 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0715 01:28:15.014356 139991156664192 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0715 01:28:15.014580 139991156664192 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0715 01:28:16.787422 139991156664192 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0715 01:28:16.787668 139991156664192 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0715 01:28:17.709818 139991156664192 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0715 01:28:17.805209 139991156664192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0715 01:28:17.936892 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0715 01:28:17.937113 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0715 01:28:17.937223 139991156664192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0715 01:28:17.939272 139991156664192 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0715 01:28:17.960972 139991156664192 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0715 01:28:17.961182 139991156664192 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0715 01:28:18.329035 139991156664192 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0715 01:28:18.329252 139991156664192 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0715 01:28:19.121794 139991156664192 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0715 01:28:19.122045 139991156664192 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0715 01:28:19.896610 139991156664192 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0715 01:28:19.896821 139991156664192 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0715 01:28:21.066924 139991156664192 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0715 01:28:21.067164 139991156664192 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0715 01:28:22.397486 139991156664192 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0715 01:28:22.397694 139991156664192 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0715 01:28:24.579693 139991156664192 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0715 01:28:24.579974 139991156664192 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0715 01:28:25.528452 139991156664192 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0715 01:28:25.631210 139991156664192 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 42.79s\n",
            "I0715 01:28:25.783618 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 42.79s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0715 01:28:25.790552 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0715 01:28:25.792754 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0715 01:28:25.793746 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0715 01:28:25.795920 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0715 01:28:25.797863 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0715 01:28:25.798572 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0715 01:28:25.799834 139991156664192 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 54.776s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "#run model builder test\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4S4aP0-09Ci"
      },
      "source": [
        "This code helps visualize the prediction and box bounding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "VaH9tVsR05tD"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path.\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "  \"\"\"Wrapper function to visualize detections.\n",
        "\n",
        "  Args:\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    boxes: a numpy array of shape [N, 4]\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
        "      and match the keys in the label map.\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
        "      this function assumes that the boxes to be plotted are groundtruth\n",
        "      boxes and plot all boxes as black with no classes or scores.\n",
        "    category_index: a dict containing category dictionaries (each holding\n",
        "      category index `id` and category name `name`) keyed by category indices.\n",
        "    figsize: size for the figure.\n",
        "    image_name: a name for the image file.\n",
        "  \"\"\"\n",
        "  image_np_with_annotations = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_annotations,\n",
        "      boxes,\n",
        "      classes,\n",
        "      scores,\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8)\n",
        "  if image_name:\n",
        "    plt.imsave(image_name, image_np_with_annotations)\n",
        "  else:\n",
        "    plt.imshow(image_np_with_annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7GS4uat1d3U"
      },
      "source": [
        "Preparation Of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIb-SByTlMI1",
        "outputId": "499f7163-6579-48f4-b389-58e1def9067b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.7/dist-packages (0.2.8)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.28.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.1.2.30 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.1.2.30)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2021.5.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: urllib3==1.26.6 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.26.6)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.9.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.20.0)\n",
            "Collecting Pillow==8.4.0\n",
            "  Using cached Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (5.4.1)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.1.0)\n",
            "Installing collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in BARCA-PLAYER-IDENTIFICATION--1 to tfrecord: 100% [651122 / 651122] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to BARCA-PLAYER-IDENTIFICATION--1 in tfrecord:: 100%|██████████| 11/11 [00:00<00:00, 1918.95it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"B8QXQaigq9lZkz5H77w6\")\n",
        "project = rf.workspace(\"charles2994-spdui\").project(\"barca-player-identification\")\n",
        "dataset = project.version(1).download(\"tfrecord\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "outputs": [],
      "source": [
        "# NOTE: Tfrecords folder for BARCELONA \n",
        "test_record_fname = '/content/BARCA-PLAYER-IDENTIFICATION--1/test/BARCELONA-.tfrecord'\n",
        "train_record_fname = '/content/BARCA-PLAYER-IDENTIFICATION--1/train/BARCELONA-.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/BARCA-PLAYER-IDENTIFICATION--1/test/BARCELONA-_label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biVlEgtF35Z8"
      },
      "source": [
        "Configure the EfficientDet for customization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "S8BP4yPj47bp"
      },
      "outputs": [],
      "source": [
        "##change chosen model to deploy different models available in the TF2 object detection zoo\n",
        "MODELS_CONFIG = {\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 4\n",
        "    },\n",
        "    'efficientdet-d1': {\n",
        "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 4\n",
        "    },\n",
        "    'efficientdet-d2': {\n",
        "        'model_name': 'efficientdet_d2_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 4\n",
        "    },\n",
        "        'efficientdet-d3': {\n",
        "        'model_name': 'efficientdet_d3_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 4\n",
        "    }\n",
        "}\n",
        "\n",
        "#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n",
        "#if you want to scale up tot larger efficientdet models you will likely need more compute!\n",
        "chosen_model = 'efficientdet-d0'\n",
        "\n",
        "num_steps = 5000 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n",
        "num_eval_steps = 500 #Perform evaluation after so many steps\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG4TmJUVrYQ7",
        "outputId": "4ffa9d4c-3057-4913-b7ed-69fc5b2cf1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/models/research/deploy/’: File exists\n",
            "/content/models/research/deploy\n",
            "--2022-07-15 01:28:37--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.16.128, 2607:f8b0:4004:c17::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.16.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30736482 (29M) [application/x-tar]\n",
            "Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz.1’\n",
            "\n",
            "efficientdet_d0_coc 100%[===================>]  29.31M  98.5MB/s    in 0.3s    \n",
            "\n",
            "2022-07-15 01:28:37 (98.5 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz.1’ saved [30736482/30736482]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#download pretrained weights\n",
        "%mkdir \"/content/models/research/deploy/\"\n",
        "%cd \"/content/models/research/deploy/\"\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rus5YGl_5aGp",
        "outputId": "2442a821-38b3-44c6-d7fa-6c12bc1c63bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/deploy\n",
            "--2022-07-15 01:28:38--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4630 (4.5K) [text/plain]\n",
            "Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.1’\n",
            "\n",
            "ssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-15 01:28:38 (45.0 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.1’ saved [4630/4630]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#download base training configuration file\n",
        "%cd /content/models/research/deploy\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "8l-E41rV5e4h"
      },
      "outputs": [],
      "source": [
        "#prepare\n",
        "pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xh5tJIB5y2h",
        "outputId": "68a3af17-31ec-483e-e55c-7439c5b552f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8deD-PuO529K",
        "outputId": "81f3579e-b80a-490b-95ac-81edc39b2564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/deploy\n",
            "writing custom configuration file\n"
          ]
        }
      ],
      "source": [
        "#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "\n",
        "import re\n",
        "\n",
        "%cd \"/content/models/research/deploy\"\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    #fine-tune checkpoint type\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "        \n",
        "    f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp_COIV76okC",
        "outputId": "71915744-10d4-48ff-c4f9-f87be961c14b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " # SSD with EfficientNet-b0 + BiFPN feature extractor,\n",
            "# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n",
            "# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n",
            "# See Lin et al, https://arxiv.org/abs/1708.02002\n",
            "# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n",
            "#\n",
            "# Train on TPU-8\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    num_classes: 1\n",
            "    add_background_class: false\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: [1.0, 2.0, 0.5]\n",
            "        scales_per_octave: 3\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 512\n",
            "        max_dimension: 512\n",
            "        pad_to_max_dimension: true\n",
            "        }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        depth: 64\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          force_use_bias: true\n",
            "          activation: SWISH\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.01\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            scale: true\n",
            "            decay: 0.99\n",
            "            epsilon: 0.001\n",
            "          }\n",
            "        }\n",
            "        num_layers_before_predictor: 3\n",
            "        kernel_size: 3\n",
            "        use_depthwise: true\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_efficientnet-b0_bifpn_keras'\n",
            "      bifpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        num_iterations: 3\n",
            "        num_filters: 64\n",
            "      }\n",
            "      conv_hyperparams {\n",
            "        force_use_bias: true\n",
            "        activation: SWISH\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          scale: true,\n",
            "          decay: 0.99,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          alpha: 0.25\n",
            "          gamma: 1.5\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.5\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  fine_tune_checkpoint: \"/content/models/research/deploy/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n",
            "  fine_tune_checkpoint_version: V2\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  batch_size: 4\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 8\n",
            "  use_bfloat16: true\n",
            "  num_steps: 5000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_scale_crop_and_pad_to_square {\n",
            "      output_size: 512\n",
            "      scale_min: 0.1\n",
            "      scale_max: 2.0\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 8e-2\n",
            "          total_steps: 300000\n",
            "          warmup_learning_rate: .001\n",
            "          warmup_steps: 2500\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  label_map_path: \"/content/BARCA-PLAYER-IDENTIFICATION--1/test/BARCELONA-_label_map.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/BARCA-PLAYER-IDENTIFICATION--1/train/BARCELONA-.tfrecord\"\n",
            "  }\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "  batch_size: 4;\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  label_map_path: \"/content/BARCA-PLAYER-IDENTIFICATION--1/test/BARCELONA-_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/BARCA-PLAYER-IDENTIFICATION--1/test/BARCELONA-.tfrecord\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#This line of code is a sanity check for the model\n",
        "%cat /content/models/research/deploy/pipeline_file.config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5t7FcB87bBg"
      },
      "source": [
        "pipeline_file: location of custom training configuration declared below /n\n",
        "\n",
        "model_dir: the location that the tensorboard logs and saved model checkpoints will save to declared below "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vIrvUnHO7MoK"
      },
      "outputs": [],
      "source": [
        "pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n",
        "model_dir = '/content/BARCA-PLAYER-IDENTIFICATION--1/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocZ1rbYi8IlJ"
      },
      "source": [
        "num_train_steps:  /n\n",
        "\n",
        "num_eval_steps: /n\n",
        "\n",
        "RUN TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8yRDDfp8Ebi",
        "outputId": "c2acd8ce-8e8c-4ec0-a934-a4e8b29fbd59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-14 19:35:09.034317: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0714 19:35:09.041256 139913254954880 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0714 19:35:09.045169 139913254954880 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0714 19:35:09.045341 139913254954880 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "I0714 19:35:09.052407 139913254954880 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0714 19:35:09.052515 139913254954880 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0714 19:35:09.052581 139913254954880 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0714 19:35:09.056063 139913254954880 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.079862 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.088482 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.091540 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.092870 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.102900 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.108119 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.117277 139913254954880 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0714 19:35:09.117414 139913254954880 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.140640 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.141799 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.144082 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.145272 139913254954880 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0714 19:35:09.275927 139913254954880 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0714 19:35:09.276090 139913254954880 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0714 19:35:09.642368 139913254954880 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0714 19:35:09.642601 139913254954880 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0714 19:35:10.131068 139913254954880 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0714 19:35:10.131270 139913254954880 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0714 19:35:10.877943 139913254954880 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0714 19:35:10.878147 139913254954880 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0714 19:35:11.587584 139913254954880 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0714 19:35:11.588653 139913254954880 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0714 19:35:12.519249 139913254954880 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0714 19:35:12.519466 139913254954880 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0714 19:35:12.691179 139913254954880 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0714 19:35:12.764767 139913254954880 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0714 19:35:12.837844 139913254954880 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/BARCA-PLAYER-IDENTIFICATION--1/train/BARCELONA-.tfrecord']\n",
            "I0714 19:35:12.843071 139913254954880 dataset_builder.py:162] Reading unweighted datasets: ['/content/BARCA-PLAYER-IDENTIFICATION--1/train/BARCELONA-.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/BARCA-PLAYER-IDENTIFICATION--1/train/BARCELONA-.tfrecord']\n",
            "I0714 19:35:12.843296 139913254954880 dataset_builder.py:79] Reading record datasets for input file: ['/content/BARCA-PLAYER-IDENTIFICATION--1/train/BARCELONA-.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0714 19:35:12.843391 139913254954880 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0714 19:35:12.843464 139913254954880 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0714 19:35:12.845994 139913254954880 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0714 19:35:12.872064 139913254954880 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0714 19:35:27.387894 139913254954880 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0714 19:35:31.105962 139913254954880 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "W0714 19:36:04.012360 139913254954880 util.py:200] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "W0714 19:36:04.012602 139913254954880 util.py:209] Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "W0714 19:36:04.012688 139913254954880 util.py:209] Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
            "W0714 19:36:04.012755 139913254954880 util.py:209] Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n"
          ]
        }
      ],
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAi5iXDG9SHZ"
      },
      "source": [
        "EVALUATION OF MODEL FOR PERFORMANCE METRICS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPIdZHHo9l46"
      },
      "source": [
        "Should show loss grapghs for inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7yIDh109iNx",
        "outputId": "d15dfda2-fbba-49f7-dae2-9f117823708f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/BARCA-PLAYER-IDENTIFICATION--1/train/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72zEfrGY-GtR"
      },
      "source": [
        "CODESECTIONS BELOW HELP CHOOSE A CHECKPOINT AND EXPORT TO A .PY file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1yiu_du-veC",
        "outputId": "f3a844ab-73cb-460f-a889-b1961dc1bd5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BARCELONA-_label_map.pbtxt  BARCELONA-.tfrecord\n"
          ]
        }
      ],
      "source": [
        "#see where the model saved weights\n",
        "%ls '/content/BARCA-PLAYER-IDENTIFICATION--1/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKIS3p05h6PA",
        "outputId": "92494fbf-0d87-4aec-9032-7a4ba86160a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BARCA-PLAYER-IDENTIFICATION--1/train\n",
            "2022-07-15 01:28:52.879684: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "I0715 01:28:52.904416 139941470455680 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0715 01:28:52.904725 139941470455680 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0715 01:28:52.904827 139941470455680 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0715 01:28:52.911785 139941470455680 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0715 01:28:52.960911 139941470455680 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0715 01:28:52.961166 139941470455680 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0715 01:28:53.103902 139941470455680 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0715 01:28:53.104562 139941470455680 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0715 01:28:53.654544 139941470455680 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0715 01:28:53.654810 139941470455680 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0715 01:28:54.117501 139941470455680 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0715 01:28:54.117729 139941470455680 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0715 01:28:54.598565 139941470455680 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0715 01:28:54.598780 139941470455680 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0715 01:28:55.521903 139941470455680 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0715 01:28:55.522170 139941470455680 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0715 01:28:56.609791 139941470455680 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0715 01:28:56.610102 139941470455680 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0715 01:28:56.901338 139941470455680 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0715 01:28:57.049267 139941470455680 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0715 01:28:57.437252 139941470455680 deprecation.py:628] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/exporter_main_v2.py\", line 164, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/exporter_main_v2.py\", line 160, in main\n",
            "    FLAGS.side_input_types, FLAGS.side_input_names)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/exporter_lib_v2.py\", line 271, in export_inference_graph\n",
            "    status.assert_existing_objects_matched()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\", line 949, in assert_existing_objects_matched\n",
            "    \"No checkpoint specified (save_path=None); nothing is being restored.\")\n",
            "AssertionError: No checkpoint specified (save_path=None); nothing is being restored.\n"
          ]
        }
      ],
      "source": [
        "#run conversion script\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = '/content/drive/MyDrive/SOCCER_Object_Detection/Barcelona_model'\n",
        "\n",
        "#place the model weights you would like to export here\n",
        "last_model_path = '/content/BARCA-PLAYER-IDENTIFICATION--1/train'\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NSHIqy4_EZa",
        "outputId": "3e6bf827-9301-4280-88a7-fcf4df13e4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcheckpoint\u001b[0m/  pipeline.config  \u001b[01;34msaved_model\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls '/content/drive/MyDrive/SOCCER_Object_Detection/Barcelona'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wBwaz8nmomZ"
      },
      "source": [
        "TRY ON TEST IMAGES "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "gQr78tj2FLj7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "vidcap = cv2.VideoCapture('/content/drive/MyDrive/SOCCER_Object_Detection/deepsort_30sec (1).mp4')\n",
        "count = 0 \n",
        "def getFrame(sec):\n",
        "   vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "   hasFrames,image = vidcap.read()\n",
        "   if hasFrames:\n",
        "       cv2.imwrite(\"/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test\"+str(count)+\".jpg\", image)     # save frame as JPG file\n",
        "   return hasFrames\n",
        "sec = 2\n",
        "frameRate = 2 #//it will capture image in each 0.5 second\n",
        "count=88\n",
        "success = getFrame(sec)\n",
        "while success:\n",
        "   count = count + 1\n",
        "   sec = sec + frameRate\n",
        "   sec = round(sec, 2)\n",
        "   success = getFrame(sec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "lJy_MHGbm7Bs"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import cv2\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "TEpaigpBkarF"
      },
      "outputs": [],
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "q3k2AZswku9I"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name, \n",
        "    origin=base_url + model_file,\n",
        "    untar=True)\n",
        "\n",
        "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "  model = tf.saved_model.load(str(model_dir))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "8oVLe0qUlOu-"
      },
      "outputs": [],
      "source": [
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = '/content/BARCA-PLAYER-IDENTIFICATION--1/test/BARCELONA-_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRBeLsTlnI7m",
        "outputId": "4db2fca3-6b93-4e12-81da-693de28c6a67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame100.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame101.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame88.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame89.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame90.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame91.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame92.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame93.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame94.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame95.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame96.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame97.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame98.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Frame99.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test100.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test101.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test88.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test89.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test90.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test91.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test92.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test93.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test94.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test95.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test96.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test97.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test98.jpg'),\n",
              " PosixPath('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/Test99.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('/content/drive/MyDrive/SOCCER_Object_Detection/Frames')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "tz55jCu2oL4_"
      },
      "outputs": [],
      "source": [
        "#model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "#detection_model = load_model(model_name)\n",
        "detection_model = tf.saved_model.load('/content/drive/MyDrive/SOCCER_Object_Detection/Barcelona/saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu5nuCJDqeDg",
        "outputId": "f9a70a78-4828-463c-ba69-7dba070ea6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor 'input_tensor:0' shape=(1, None, None, 3) dtype=uint8>, <tf.Tensor 'unknown:0' shape=() dtype=resource>, <tf.Tensor 'unknown_0:0' shape=() dtype=resource>, <tf.Tensor 'unknown_1:0' shape=() dtype=resource>, <tf.Tensor 'unknown_2:0' shape=() dtype=resource>, <tf.Tensor 'unknown_3:0' shape=() dtype=resource>, <tf.Tensor 'unknown_4:0' shape=() dtype=resource>, <tf.Tensor 'unknown_5:0' shape=() dtype=resource>, <tf.Tensor 'unknown_6:0' shape=() dtype=resource>, <tf.Tensor 'unknown_7:0' shape=() dtype=resource>, <tf.Tensor 'unknown_8:0' shape=() dtype=resource>, <tf.Tensor 'unknown_9:0' shape=() dtype=resource>, <tf.Tensor 'unknown_10:0' shape=() dtype=resource>, <tf.Tensor 'unknown_11:0' shape=() dtype=resource>, <tf.Tensor 'unknown_12:0' shape=() dtype=resource>, <tf.Tensor 'unknown_13:0' shape=() dtype=resource>, <tf.Tensor 'unknown_14:0' shape=() dtype=resource>, <tf.Tensor 'unknown_15:0' shape=() dtype=resource>, <tf.Tensor 'unknown_16:0' shape=() dtype=resource>, <tf.Tensor 'unknown_17:0' shape=() dtype=resource>, <tf.Tensor 'unknown_18:0' shape=() dtype=resource>, <tf.Tensor 'unknown_19:0' shape=() dtype=resource>, <tf.Tensor 'unknown_20:0' shape=() dtype=resource>, <tf.Tensor 'unknown_21:0' shape=() dtype=resource>, <tf.Tensor 'unknown_22:0' shape=() dtype=resource>, <tf.Tensor 'unknown_23:0' shape=() dtype=resource>, <tf.Tensor 'unknown_24:0' shape=() dtype=resource>, <tf.Tensor 'unknown_25:0' shape=() dtype=resource>, <tf.Tensor 'unknown_26:0' shape=() dtype=resource>, <tf.Tensor 'unknown_27:0' shape=() dtype=resource>, <tf.Tensor 'unknown_28:0' shape=() dtype=resource>, <tf.Tensor 'unknown_29:0' shape=() dtype=resource>, <tf.Tensor 'unknown_30:0' shape=() dtype=resource>, <tf.Tensor 'unknown_31:0' shape=() dtype=resource>, <tf.Tensor 'unknown_32:0' shape=() dtype=resource>, <tf.Tensor 'unknown_33:0' shape=() dtype=resource>, <tf.Tensor 'unknown_34:0' shape=() dtype=resource>, <tf.Tensor 'unknown_35:0' shape=() dtype=resource>, <tf.Tensor 'unknown_36:0' shape=() dtype=resource>, <tf.Tensor 'unknown_37:0' shape=() dtype=resource>, <tf.Tensor 'unknown_38:0' shape=() dtype=resource>, <tf.Tensor 'unknown_39:0' shape=() dtype=resource>, <tf.Tensor 'unknown_40:0' shape=() dtype=resource>, <tf.Tensor 'unknown_41:0' shape=() dtype=resource>, <tf.Tensor 'unknown_42:0' shape=() dtype=resource>, <tf.Tensor 'unknown_43:0' shape=() dtype=resource>, <tf.Tensor 'unknown_44:0' shape=() dtype=resource>, <tf.Tensor 'unknown_45:0' shape=() dtype=resource>, <tf.Tensor 'unknown_46:0' shape=() dtype=resource>, <tf.Tensor 'unknown_47:0' shape=() dtype=resource>, <tf.Tensor 'unknown_48:0' shape=() dtype=resource>, <tf.Tensor 'unknown_49:0' shape=() dtype=resource>, <tf.Tensor 'unknown_50:0' shape=() dtype=resource>, <tf.Tensor 'unknown_51:0' shape=() dtype=resource>, <tf.Tensor 'unknown_52:0' shape=() dtype=resource>, <tf.Tensor 'unknown_53:0' shape=() dtype=resource>, <tf.Tensor 'unknown_54:0' shape=() dtype=resource>, <tf.Tensor 'unknown_55:0' shape=() dtype=resource>, <tf.Tensor 'unknown_56:0' shape=() dtype=resource>, <tf.Tensor 'unknown_57:0' shape=() dtype=resource>, <tf.Tensor 'unknown_58:0' shape=() dtype=resource>, <tf.Tensor 'unknown_59:0' shape=() dtype=resource>, <tf.Tensor 'unknown_60:0' shape=() dtype=resource>, <tf.Tensor 'unknown_61:0' shape=() dtype=resource>, <tf.Tensor 'unknown_62:0' shape=() dtype=resource>, <tf.Tensor 'unknown_63:0' shape=() dtype=resource>, <tf.Tensor 'unknown_64:0' shape=() dtype=resource>, <tf.Tensor 'unknown_65:0' shape=() dtype=resource>, <tf.Tensor 'unknown_66:0' shape=() dtype=resource>, <tf.Tensor 'unknown_67:0' shape=() dtype=resource>, <tf.Tensor 'unknown_68:0' shape=() dtype=resource>, <tf.Tensor 'unknown_69:0' shape=() dtype=resource>, <tf.Tensor 'unknown_70:0' shape=() dtype=resource>, <tf.Tensor 'unknown_71:0' shape=() dtype=resource>, <tf.Tensor 'unknown_72:0' shape=() dtype=resource>, <tf.Tensor 'unknown_73:0' shape=() dtype=resource>, <tf.Tensor 'unknown_74:0' shape=() dtype=resource>, <tf.Tensor 'unknown_75:0' shape=() dtype=resource>, <tf.Tensor 'unknown_76:0' shape=() dtype=resource>, <tf.Tensor 'unknown_77:0' shape=() dtype=resource>, <tf.Tensor 'unknown_78:0' shape=() dtype=resource>, <tf.Tensor 'unknown_79:0' shape=() dtype=resource>, <tf.Tensor 'unknown_80:0' shape=() dtype=resource>, <tf.Tensor 'unknown_81:0' shape=() dtype=resource>, <tf.Tensor 'unknown_82:0' shape=() dtype=resource>, <tf.Tensor 'unknown_83:0' shape=() dtype=resource>, <tf.Tensor 'unknown_84:0' shape=() dtype=resource>, <tf.Tensor 'unknown_85:0' shape=() dtype=resource>, <tf.Tensor 'unknown_86:0' shape=() dtype=resource>, <tf.Tensor 'unknown_87:0' shape=() dtype=resource>, <tf.Tensor 'unknown_88:0' shape=() dtype=resource>, <tf.Tensor 'unknown_89:0' shape=() dtype=resource>, <tf.Tensor 'unknown_90:0' shape=() dtype=resource>, <tf.Tensor 'unknown_91:0' shape=() dtype=resource>, <tf.Tensor 'unknown_92:0' shape=() dtype=resource>, <tf.Tensor 'unknown_93:0' shape=() dtype=resource>, <tf.Tensor 'unknown_94:0' shape=() dtype=resource>, <tf.Tensor 'unknown_95:0' shape=() dtype=resource>, <tf.Tensor 'unknown_96:0' shape=() dtype=resource>, <tf.Tensor 'unknown_97:0' shape=() dtype=resource>, <tf.Tensor 'unknown_98:0' shape=() dtype=resource>, <tf.Tensor 'unknown_99:0' shape=() dtype=resource>, <tf.Tensor 'unknown_100:0' shape=() dtype=resource>, <tf.Tensor 'unknown_101:0' shape=() dtype=resource>, <tf.Tensor 'unknown_102:0' shape=() dtype=resource>, <tf.Tensor 'unknown_103:0' shape=() dtype=resource>, <tf.Tensor 'unknown_104:0' shape=() dtype=resource>, <tf.Tensor 'unknown_105:0' shape=() dtype=resource>, <tf.Tensor 'unknown_106:0' shape=() dtype=resource>, <tf.Tensor 'unknown_107:0' shape=() dtype=resource>, <tf.Tensor 'unknown_108:0' shape=() dtype=resource>, <tf.Tensor 'unknown_109:0' shape=() dtype=resource>, <tf.Tensor 'unknown_110:0' shape=() dtype=resource>, <tf.Tensor 'unknown_111:0' shape=() dtype=resource>, <tf.Tensor 'unknown_112:0' shape=() dtype=resource>, <tf.Tensor 'unknown_113:0' shape=() dtype=resource>, <tf.Tensor 'unknown_114:0' shape=() dtype=resource>, <tf.Tensor 'unknown_115:0' shape=() dtype=resource>, <tf.Tensor 'unknown_116:0' shape=() dtype=resource>, <tf.Tensor 'unknown_117:0' shape=() dtype=resource>, <tf.Tensor 'unknown_118:0' shape=() dtype=resource>, <tf.Tensor 'unknown_119:0' shape=() dtype=resource>, <tf.Tensor 'unknown_120:0' shape=() dtype=resource>, <tf.Tensor 'unknown_121:0' shape=() dtype=resource>, <tf.Tensor 'unknown_122:0' shape=() dtype=resource>, <tf.Tensor 'unknown_123:0' shape=() dtype=resource>, <tf.Tensor 'unknown_124:0' shape=() dtype=resource>, <tf.Tensor 'unknown_125:0' shape=() dtype=resource>, <tf.Tensor 'unknown_126:0' shape=() dtype=resource>, <tf.Tensor 'unknown_127:0' shape=() dtype=resource>, <tf.Tensor 'unknown_128:0' shape=() dtype=resource>, <tf.Tensor 'unknown_129:0' shape=() dtype=resource>, <tf.Tensor 'unknown_130:0' shape=() dtype=resource>, <tf.Tensor 'unknown_131:0' shape=() dtype=resource>, <tf.Tensor 'unknown_132:0' shape=() dtype=resource>, <tf.Tensor 'unknown_133:0' shape=() dtype=resource>, <tf.Tensor 'unknown_134:0' shape=() dtype=resource>, <tf.Tensor 'unknown_135:0' shape=() dtype=resource>, <tf.Tensor 'unknown_136:0' shape=() dtype=resource>, <tf.Tensor 'unknown_137:0' shape=() dtype=resource>, <tf.Tensor 'unknown_138:0' shape=() dtype=resource>, <tf.Tensor 'unknown_139:0' shape=() dtype=resource>, <tf.Tensor 'unknown_140:0' shape=() dtype=resource>, <tf.Tensor 'unknown_141:0' shape=() dtype=resource>, <tf.Tensor 'unknown_142:0' shape=() dtype=resource>, <tf.Tensor 'unknown_143:0' shape=() dtype=resource>, <tf.Tensor 'unknown_144:0' shape=() dtype=resource>, <tf.Tensor 'unknown_145:0' shape=() dtype=resource>, <tf.Tensor 'unknown_146:0' shape=() dtype=resource>, <tf.Tensor 'unknown_147:0' shape=() dtype=resource>, <tf.Tensor 'unknown_148:0' shape=() dtype=resource>, <tf.Tensor 'unknown_149:0' shape=() dtype=resource>, <tf.Tensor 'unknown_150:0' shape=() dtype=resource>, <tf.Tensor 'unknown_151:0' shape=() dtype=resource>, <tf.Tensor 'unknown_152:0' shape=() dtype=resource>, <tf.Tensor 'unknown_153:0' shape=() dtype=resource>, <tf.Tensor 'unknown_154:0' shape=() dtype=resource>, <tf.Tensor 'unknown_155:0' shape=() dtype=resource>, <tf.Tensor 'unknown_156:0' shape=() dtype=resource>, <tf.Tensor 'unknown_157:0' shape=() dtype=resource>, <tf.Tensor 'unknown_158:0' shape=() dtype=resource>, <tf.Tensor 'unknown_159:0' shape=() dtype=resource>, <tf.Tensor 'unknown_160:0' shape=() dtype=resource>, <tf.Tensor 'unknown_161:0' shape=() dtype=resource>, <tf.Tensor 'unknown_162:0' shape=() dtype=resource>, <tf.Tensor 'unknown_163:0' shape=() dtype=resource>, <tf.Tensor 'unknown_164:0' shape=() dtype=resource>, <tf.Tensor 'unknown_165:0' shape=() dtype=resource>, <tf.Tensor 'unknown_166:0' shape=() dtype=resource>, <tf.Tensor 'unknown_167:0' shape=() dtype=resource>, <tf.Tensor 'unknown_168:0' shape=() dtype=resource>, <tf.Tensor 'unknown_169:0' shape=() dtype=resource>, <tf.Tensor 'unknown_170:0' shape=() dtype=resource>, <tf.Tensor 'unknown_171:0' shape=() dtype=resource>, <tf.Tensor 'unknown_172:0' shape=() dtype=resource>, <tf.Tensor 'unknown_173:0' shape=() dtype=resource>, <tf.Tensor 'unknown_174:0' shape=() dtype=resource>, <tf.Tensor 'unknown_175:0' shape=() dtype=resource>, <tf.Tensor 'unknown_176:0' shape=() dtype=resource>, <tf.Tensor 'unknown_177:0' shape=() dtype=resource>, <tf.Tensor 'unknown_178:0' shape=() dtype=resource>, <tf.Tensor 'unknown_179:0' shape=() dtype=resource>, <tf.Tensor 'unknown_180:0' shape=() dtype=resource>, <tf.Tensor 'unknown_181:0' shape=() dtype=resource>, <tf.Tensor 'unknown_182:0' shape=() dtype=resource>, <tf.Tensor 'unknown_183:0' shape=() dtype=resource>, <tf.Tensor 'unknown_184:0' shape=() dtype=resource>, <tf.Tensor 'unknown_185:0' shape=() dtype=resource>, <tf.Tensor 'unknown_186:0' shape=() dtype=resource>, <tf.Tensor 'unknown_187:0' shape=() dtype=resource>, <tf.Tensor 'unknown_188:0' shape=() dtype=resource>, <tf.Tensor 'unknown_189:0' shape=() dtype=resource>, <tf.Tensor 'unknown_190:0' shape=() dtype=resource>, <tf.Tensor 'unknown_191:0' shape=() dtype=resource>, <tf.Tensor 'unknown_192:0' shape=() dtype=resource>, <tf.Tensor 'unknown_193:0' shape=() dtype=resource>, <tf.Tensor 'unknown_194:0' shape=() dtype=resource>, <tf.Tensor 'unknown_195:0' shape=() dtype=resource>, <tf.Tensor 'unknown_196:0' shape=() dtype=resource>, <tf.Tensor 'unknown_197:0' shape=() dtype=resource>, <tf.Tensor 'unknown_198:0' shape=() dtype=resource>, <tf.Tensor 'unknown_199:0' shape=() dtype=resource>, <tf.Tensor 'unknown_200:0' shape=() dtype=resource>, <tf.Tensor 'unknown_201:0' shape=() dtype=resource>, <tf.Tensor 'unknown_202:0' shape=() dtype=resource>, <tf.Tensor 'unknown_203:0' shape=() dtype=resource>, <tf.Tensor 'unknown_204:0' shape=() dtype=resource>, <tf.Tensor 'unknown_205:0' shape=() dtype=resource>, <tf.Tensor 'unknown_206:0' shape=() dtype=resource>, <tf.Tensor 'unknown_207:0' shape=() dtype=resource>, <tf.Tensor 'unknown_208:0' shape=() dtype=resource>, <tf.Tensor 'unknown_209:0' shape=() dtype=resource>, <tf.Tensor 'unknown_210:0' shape=() dtype=resource>, <tf.Tensor 'unknown_211:0' shape=() dtype=resource>, <tf.Tensor 'unknown_212:0' shape=() dtype=resource>, <tf.Tensor 'unknown_213:0' shape=() dtype=resource>, <tf.Tensor 'unknown_214:0' shape=() dtype=resource>, <tf.Tensor 'unknown_215:0' shape=() dtype=resource>, <tf.Tensor 'unknown_216:0' shape=() dtype=resource>, <tf.Tensor 'unknown_217:0' shape=() dtype=resource>, <tf.Tensor 'unknown_218:0' shape=() dtype=resource>, <tf.Tensor 'unknown_219:0' shape=() dtype=resource>, <tf.Tensor 'unknown_220:0' shape=() dtype=resource>, <tf.Tensor 'unknown_221:0' shape=() dtype=resource>, <tf.Tensor 'unknown_222:0' shape=() dtype=resource>, <tf.Tensor 'unknown_223:0' shape=() dtype=resource>, <tf.Tensor 'unknown_224:0' shape=() dtype=resource>, <tf.Tensor 'unknown_225:0' shape=() dtype=resource>, <tf.Tensor 'unknown_226:0' shape=() dtype=resource>, <tf.Tensor 'unknown_227:0' shape=() dtype=resource>, <tf.Tensor 'unknown_228:0' shape=() dtype=resource>, <tf.Tensor 'unknown_229:0' shape=() dtype=resource>, <tf.Tensor 'unknown_230:0' shape=() dtype=resource>, <tf.Tensor 'unknown_231:0' shape=() dtype=resource>, <tf.Tensor 'unknown_232:0' shape=() dtype=resource>, <tf.Tensor 'unknown_233:0' shape=() dtype=resource>, <tf.Tensor 'unknown_234:0' shape=() dtype=resource>, <tf.Tensor 'unknown_235:0' shape=() dtype=resource>, <tf.Tensor 'unknown_236:0' shape=() dtype=resource>, <tf.Tensor 'unknown_237:0' shape=() dtype=resource>, <tf.Tensor 'unknown_238:0' shape=() dtype=resource>, <tf.Tensor 'unknown_239:0' shape=() dtype=resource>, <tf.Tensor 'unknown_240:0' shape=() dtype=resource>, <tf.Tensor 'unknown_241:0' shape=() dtype=resource>, <tf.Tensor 'unknown_242:0' shape=() dtype=resource>, <tf.Tensor 'unknown_243:0' shape=() dtype=resource>, <tf.Tensor 'unknown_244:0' shape=() dtype=resource>, <tf.Tensor 'unknown_245:0' shape=() dtype=resource>, <tf.Tensor 'unknown_246:0' shape=() dtype=resource>, <tf.Tensor 'unknown_247:0' shape=() dtype=resource>, <tf.Tensor 'unknown_248:0' shape=() dtype=resource>, <tf.Tensor 'unknown_249:0' shape=() dtype=resource>, <tf.Tensor 'unknown_250:0' shape=() dtype=resource>, <tf.Tensor 'unknown_251:0' shape=() dtype=resource>, <tf.Tensor 'unknown_252:0' shape=() dtype=resource>, <tf.Tensor 'unknown_253:0' shape=() dtype=resource>, <tf.Tensor 'unknown_254:0' shape=() dtype=resource>, <tf.Tensor 'unknown_255:0' shape=() dtype=resource>, <tf.Tensor 'unknown_256:0' shape=() dtype=resource>, <tf.Tensor 'unknown_257:0' shape=() dtype=resource>, <tf.Tensor 'unknown_258:0' shape=() dtype=resource>, <tf.Tensor 'unknown_259:0' shape=() dtype=resource>, <tf.Tensor 'unknown_260:0' shape=() dtype=resource>, <tf.Tensor 'unknown_261:0' shape=() dtype=resource>, <tf.Tensor 'unknown_262:0' shape=() dtype=resource>, <tf.Tensor 'unknown_263:0' shape=() dtype=resource>, <tf.Tensor 'unknown_264:0' shape=() dtype=resource>, <tf.Tensor 'unknown_265:0' shape=() dtype=resource>, <tf.Tensor 'unknown_266:0' shape=() dtype=resource>, <tf.Tensor 'unknown_267:0' shape=() dtype=resource>, <tf.Tensor 'unknown_268:0' shape=() dtype=resource>, <tf.Tensor 'unknown_269:0' shape=() dtype=resource>, <tf.Tensor 'unknown_270:0' shape=() dtype=resource>, <tf.Tensor 'unknown_271:0' shape=() dtype=resource>, <tf.Tensor 'unknown_272:0' shape=() dtype=resource>, <tf.Tensor 'unknown_273:0' shape=() dtype=resource>, <tf.Tensor 'unknown_274:0' shape=() dtype=resource>, <tf.Tensor 'unknown_275:0' shape=() dtype=resource>, <tf.Tensor 'unknown_276:0' shape=() dtype=resource>, <tf.Tensor 'unknown_277:0' shape=() dtype=resource>, <tf.Tensor 'unknown_278:0' shape=() dtype=resource>, <tf.Tensor 'unknown_279:0' shape=() dtype=resource>, <tf.Tensor 'unknown_280:0' shape=() dtype=resource>, <tf.Tensor 'unknown_281:0' shape=() dtype=resource>, <tf.Tensor 'unknown_282:0' shape=() dtype=resource>, <tf.Tensor 'unknown_283:0' shape=() dtype=resource>, <tf.Tensor 'unknown_284:0' shape=() dtype=resource>, <tf.Tensor 'unknown_285:0' shape=() dtype=resource>, <tf.Tensor 'unknown_286:0' shape=() dtype=resource>, <tf.Tensor 'unknown_287:0' shape=() dtype=resource>, <tf.Tensor 'unknown_288:0' shape=() dtype=resource>, <tf.Tensor 'unknown_289:0' shape=() dtype=resource>, <tf.Tensor 'unknown_290:0' shape=() dtype=resource>, <tf.Tensor 'unknown_291:0' shape=() dtype=resource>, <tf.Tensor 'unknown_292:0' shape=() dtype=resource>, <tf.Tensor 'unknown_293:0' shape=() dtype=resource>, <tf.Tensor 'unknown_294:0' shape=() dtype=resource>, <tf.Tensor 'unknown_295:0' shape=() dtype=resource>, <tf.Tensor 'unknown_296:0' shape=() dtype=resource>, <tf.Tensor 'unknown_297:0' shape=() dtype=resource>, <tf.Tensor 'unknown_298:0' shape=() dtype=resource>, <tf.Tensor 'unknown_299:0' shape=() dtype=resource>, <tf.Tensor 'unknown_300:0' shape=() dtype=resource>, <tf.Tensor 'unknown_301:0' shape=() dtype=resource>, <tf.Tensor 'unknown_302:0' shape=() dtype=resource>, <tf.Tensor 'unknown_303:0' shape=() dtype=resource>, <tf.Tensor 'unknown_304:0' shape=() dtype=resource>, <tf.Tensor 'unknown_305:0' shape=() dtype=resource>, <tf.Tensor 'unknown_306:0' shape=() dtype=resource>, <tf.Tensor 'unknown_307:0' shape=() dtype=resource>, <tf.Tensor 'unknown_308:0' shape=() dtype=resource>, <tf.Tensor 'unknown_309:0' shape=() dtype=resource>, <tf.Tensor 'unknown_310:0' shape=() dtype=resource>, <tf.Tensor 'unknown_311:0' shape=() dtype=resource>, <tf.Tensor 'unknown_312:0' shape=() dtype=resource>, <tf.Tensor 'unknown_313:0' shape=() dtype=resource>, <tf.Tensor 'unknown_314:0' shape=() dtype=resource>, <tf.Tensor 'unknown_315:0' shape=() dtype=resource>, <tf.Tensor 'unknown_316:0' shape=() dtype=resource>, <tf.Tensor 'unknown_317:0' shape=() dtype=resource>, <tf.Tensor 'unknown_318:0' shape=() dtype=resource>, <tf.Tensor 'unknown_319:0' shape=() dtype=resource>, <tf.Tensor 'unknown_320:0' shape=() dtype=resource>, <tf.Tensor 'unknown_321:0' shape=() dtype=resource>, <tf.Tensor 'unknown_322:0' shape=() dtype=resource>, <tf.Tensor 'unknown_323:0' shape=() dtype=resource>, <tf.Tensor 'unknown_324:0' shape=() dtype=resource>, <tf.Tensor 'unknown_325:0' shape=() dtype=resource>, <tf.Tensor 'unknown_326:0' shape=() dtype=resource>, <tf.Tensor 'unknown_327:0' shape=() dtype=resource>, <tf.Tensor 'unknown_328:0' shape=() dtype=resource>, <tf.Tensor 'unknown_329:0' shape=() dtype=resource>, <tf.Tensor 'unknown_330:0' shape=() dtype=resource>, <tf.Tensor 'unknown_331:0' shape=() dtype=resource>, <tf.Tensor 'unknown_332:0' shape=() dtype=resource>, <tf.Tensor 'unknown_333:0' shape=() dtype=resource>, <tf.Tensor 'unknown_334:0' shape=() dtype=resource>, <tf.Tensor 'unknown_335:0' shape=() dtype=resource>, <tf.Tensor 'unknown_336:0' shape=() dtype=resource>, <tf.Tensor 'unknown_337:0' shape=() dtype=resource>, <tf.Tensor 'unknown_338:0' shape=() dtype=resource>, <tf.Tensor 'unknown_339:0' shape=() dtype=resource>, <tf.Tensor 'unknown_340:0' shape=() dtype=resource>, <tf.Tensor 'unknown_341:0' shape=() dtype=resource>, <tf.Tensor 'unknown_342:0' shape=() dtype=resource>, <tf.Tensor 'unknown_343:0' shape=() dtype=resource>, <tf.Tensor 'unknown_344:0' shape=() dtype=resource>, <tf.Tensor 'unknown_345:0' shape=() dtype=resource>, <tf.Tensor 'unknown_346:0' shape=() dtype=resource>, <tf.Tensor 'unknown_347:0' shape=() dtype=resource>, <tf.Tensor 'unknown_348:0' shape=() dtype=resource>, <tf.Tensor 'unknown_349:0' shape=() dtype=resource>, <tf.Tensor 'unknown_350:0' shape=() dtype=resource>, <tf.Tensor 'unknown_351:0' shape=() dtype=resource>, <tf.Tensor 'unknown_352:0' shape=() dtype=resource>, <tf.Tensor 'unknown_353:0' shape=() dtype=resource>, <tf.Tensor 'unknown_354:0' shape=() dtype=resource>, <tf.Tensor 'unknown_355:0' shape=() dtype=resource>, <tf.Tensor 'unknown_356:0' shape=() dtype=resource>, <tf.Tensor 'unknown_357:0' shape=() dtype=resource>, <tf.Tensor 'unknown_358:0' shape=() dtype=resource>, <tf.Tensor 'unknown_359:0' shape=() dtype=resource>, <tf.Tensor 'unknown_360:0' shape=() dtype=resource>, <tf.Tensor 'unknown_361:0' shape=() dtype=resource>, <tf.Tensor 'unknown_362:0' shape=() dtype=resource>, <tf.Tensor 'unknown_363:0' shape=() dtype=resource>, <tf.Tensor 'unknown_364:0' shape=() dtype=resource>, <tf.Tensor 'unknown_365:0' shape=() dtype=resource>, <tf.Tensor 'unknown_366:0' shape=() dtype=resource>, <tf.Tensor 'unknown_367:0' shape=() dtype=resource>, <tf.Tensor 'unknown_368:0' shape=() dtype=resource>, <tf.Tensor 'unknown_369:0' shape=() dtype=resource>, <tf.Tensor 'unknown_370:0' shape=() dtype=resource>, <tf.Tensor 'unknown_371:0' shape=() dtype=resource>, <tf.Tensor 'unknown_372:0' shape=() dtype=resource>, <tf.Tensor 'unknown_373:0' shape=() dtype=resource>, <tf.Tensor 'unknown_374:0' shape=() dtype=resource>, <tf.Tensor 'unknown_375:0' shape=() dtype=resource>, <tf.Tensor 'unknown_376:0' shape=() dtype=resource>, <tf.Tensor 'unknown_377:0' shape=() dtype=resource>, <tf.Tensor 'unknown_378:0' shape=() dtype=resource>, <tf.Tensor 'unknown_379:0' shape=() dtype=resource>, <tf.Tensor 'unknown_380:0' shape=() dtype=resource>, <tf.Tensor 'unknown_381:0' shape=() dtype=resource>, <tf.Tensor 'unknown_382:0' shape=() dtype=resource>, <tf.Tensor 'unknown_383:0' shape=() dtype=resource>, <tf.Tensor 'unknown_384:0' shape=() dtype=resource>, <tf.Tensor 'unknown_385:0' shape=() dtype=resource>, <tf.Tensor 'unknown_386:0' shape=() dtype=resource>, <tf.Tensor 'unknown_387:0' shape=() dtype=resource>, <tf.Tensor 'unknown_388:0' shape=() dtype=resource>, <tf.Tensor 'unknown_389:0' shape=() dtype=resource>, <tf.Tensor 'unknown_390:0' shape=() dtype=resource>, <tf.Tensor 'unknown_391:0' shape=() dtype=resource>, <tf.Tensor 'unknown_392:0' shape=() dtype=resource>, <tf.Tensor 'unknown_393:0' shape=() dtype=resource>, <tf.Tensor 'unknown_394:0' shape=() dtype=resource>, <tf.Tensor 'unknown_395:0' shape=() dtype=resource>, <tf.Tensor 'unknown_396:0' shape=() dtype=resource>, <tf.Tensor 'unknown_397:0' shape=() dtype=resource>, <tf.Tensor 'unknown_398:0' shape=() dtype=resource>, <tf.Tensor 'unknown_399:0' shape=() dtype=resource>, <tf.Tensor 'unknown_400:0' shape=() dtype=resource>, <tf.Tensor 'unknown_401:0' shape=() dtype=resource>, <tf.Tensor 'unknown_402:0' shape=() dtype=resource>, <tf.Tensor 'unknown_403:0' shape=() dtype=resource>, <tf.Tensor 'unknown_404:0' shape=() dtype=resource>, <tf.Tensor 'unknown_405:0' shape=() dtype=resource>, <tf.Tensor 'unknown_406:0' shape=() dtype=resource>, <tf.Tensor 'unknown_407:0' shape=() dtype=resource>, <tf.Tensor 'unknown_408:0' shape=() dtype=resource>, <tf.Tensor 'unknown_409:0' shape=() dtype=resource>, <tf.Tensor 'unknown_410:0' shape=() dtype=resource>, <tf.Tensor 'unknown_411:0' shape=() dtype=resource>, <tf.Tensor 'unknown_412:0' shape=() dtype=resource>, <tf.Tensor 'unknown_413:0' shape=() dtype=resource>, <tf.Tensor 'unknown_414:0' shape=() dtype=resource>, <tf.Tensor 'unknown_415:0' shape=() dtype=resource>, <tf.Tensor 'unknown_416:0' shape=() dtype=resource>, <tf.Tensor 'unknown_417:0' shape=() dtype=resource>, <tf.Tensor 'unknown_418:0' shape=() dtype=resource>, <tf.Tensor 'unknown_419:0' shape=() dtype=resource>, <tf.Tensor 'unknown_420:0' shape=() dtype=resource>, <tf.Tensor 'unknown_421:0' shape=() dtype=resource>, <tf.Tensor 'unknown_422:0' shape=() dtype=resource>, <tf.Tensor 'unknown_423:0' shape=() dtype=resource>, <tf.Tensor 'unknown_424:0' shape=() dtype=resource>, <tf.Tensor 'unknown_425:0' shape=() dtype=resource>, <tf.Tensor 'unknown_426:0' shape=() dtype=resource>, <tf.Tensor 'unknown_427:0' shape=() dtype=resource>, <tf.Tensor 'unknown_428:0' shape=() dtype=resource>, <tf.Tensor 'unknown_429:0' shape=() dtype=resource>, <tf.Tensor 'unknown_430:0' shape=() dtype=resource>, <tf.Tensor 'unknown_431:0' shape=() dtype=resource>, <tf.Tensor 'unknown_432:0' shape=() dtype=resource>, <tf.Tensor 'unknown_433:0' shape=() dtype=resource>, <tf.Tensor 'unknown_434:0' shape=() dtype=resource>, <tf.Tensor 'unknown_435:0' shape=() dtype=resource>, <tf.Tensor 'unknown_436:0' shape=() dtype=resource>, <tf.Tensor 'unknown_437:0' shape=() dtype=resource>, <tf.Tensor 'unknown_438:0' shape=() dtype=resource>, <tf.Tensor 'unknown_439:0' shape=() dtype=resource>, <tf.Tensor 'unknown_440:0' shape=() dtype=resource>, <tf.Tensor 'unknown_441:0' shape=() dtype=resource>, <tf.Tensor 'unknown_442:0' shape=() dtype=resource>, <tf.Tensor 'unknown_443:0' shape=() dtype=resource>, <tf.Tensor 'unknown_444:0' shape=() dtype=resource>, <tf.Tensor 'unknown_445:0' shape=() dtype=resource>, <tf.Tensor 'unknown_446:0' shape=() dtype=resource>, <tf.Tensor 'unknown_447:0' shape=() dtype=resource>, <tf.Tensor 'unknown_448:0' shape=() dtype=resource>, <tf.Tensor 'unknown_449:0' shape=() dtype=resource>, <tf.Tensor 'unknown_450:0' shape=() dtype=resource>, <tf.Tensor 'unknown_451:0' shape=() dtype=resource>, <tf.Tensor 'unknown_452:0' shape=() dtype=resource>, <tf.Tensor 'unknown_453:0' shape=() dtype=resource>, <tf.Tensor 'unknown_454:0' shape=() dtype=resource>, <tf.Tensor 'unknown_455:0' shape=() dtype=resource>, <tf.Tensor 'unknown_456:0' shape=() dtype=resource>, <tf.Tensor 'unknown_457:0' shape=() dtype=resource>, <tf.Tensor 'unknown_458:0' shape=() dtype=resource>, <tf.Tensor 'unknown_459:0' shape=() dtype=resource>, <tf.Tensor 'unknown_460:0' shape=() dtype=resource>, <tf.Tensor 'unknown_461:0' shape=() dtype=resource>, <tf.Tensor 'unknown_462:0' shape=() dtype=resource>, <tf.Tensor 'unknown_463:0' shape=() dtype=resource>, <tf.Tensor 'unknown_464:0' shape=() dtype=resource>, <tf.Tensor 'unknown_465:0' shape=() dtype=resource>, <tf.Tensor 'unknown_466:0' shape=() dtype=resource>, <tf.Tensor 'unknown_467:0' shape=() dtype=resource>, <tf.Tensor 'unknown_468:0' shape=() dtype=resource>, <tf.Tensor 'unknown_469:0' shape=() dtype=resource>, <tf.Tensor 'unknown_470:0' shape=() dtype=resource>, <tf.Tensor 'unknown_471:0' shape=() dtype=resource>, <tf.Tensor 'unknown_472:0' shape=() dtype=resource>, <tf.Tensor 'unknown_473:0' shape=() dtype=resource>, <tf.Tensor 'unknown_474:0' shape=() dtype=resource>, <tf.Tensor 'unknown_475:0' shape=() dtype=resource>, <tf.Tensor 'unknown_476:0' shape=() dtype=resource>, <tf.Tensor 'unknown_477:0' shape=() dtype=resource>, <tf.Tensor 'unknown_478:0' shape=() dtype=resource>, <tf.Tensor 'unknown_479:0' shape=() dtype=resource>, <tf.Tensor 'unknown_480:0' shape=() dtype=resource>, <tf.Tensor 'unknown_481:0' shape=() dtype=resource>, <tf.Tensor 'unknown_482:0' shape=() dtype=resource>, <tf.Tensor 'unknown_483:0' shape=() dtype=resource>, <tf.Tensor 'unknown_484:0' shape=() dtype=resource>, <tf.Tensor 'unknown_485:0' shape=() dtype=resource>, <tf.Tensor 'unknown_486:0' shape=() dtype=resource>, <tf.Tensor 'unknown_487:0' shape=() dtype=resource>, <tf.Tensor 'unknown_488:0' shape=() dtype=resource>, <tf.Tensor 'unknown_489:0' shape=() dtype=resource>, <tf.Tensor 'unknown_490:0' shape=() dtype=resource>, <tf.Tensor 'unknown_491:0' shape=() dtype=resource>, <tf.Tensor 'unknown_492:0' shape=() dtype=resource>, <tf.Tensor 'unknown_493:0' shape=() dtype=resource>, <tf.Tensor 'unknown_494:0' shape=() dtype=resource>, <tf.Tensor 'unknown_495:0' shape=() dtype=resource>, <tf.Tensor 'unknown_496:0' shape=() dtype=resource>, <tf.Tensor 'unknown_497:0' shape=() dtype=resource>, <tf.Tensor 'unknown_498:0' shape=() dtype=resource>, <tf.Tensor 'unknown_499:0' shape=() dtype=resource>, <tf.Tensor 'unknown_500:0' shape=() dtype=resource>, <tf.Tensor 'unknown_501:0' shape=() dtype=resource>, <tf.Tensor 'unknown_502:0' shape=() dtype=resource>, <tf.Tensor 'unknown_503:0' shape=() dtype=resource>, <tf.Tensor 'unknown_504:0' shape=() dtype=resource>, <tf.Tensor 'unknown_505:0' shape=() dtype=resource>, <tf.Tensor 'unknown_506:0' shape=() dtype=resource>, <tf.Tensor 'unknown_507:0' shape=() dtype=resource>, <tf.Tensor 'unknown_508:0' shape=() dtype=resource>, <tf.Tensor 'unknown_509:0' shape=() dtype=resource>, <tf.Tensor 'unknown_510:0' shape=() dtype=resource>, <tf.Tensor 'unknown_511:0' shape=() dtype=resource>, <tf.Tensor 'unknown_512:0' shape=() dtype=resource>, <tf.Tensor 'unknown_513:0' shape=() dtype=resource>, <tf.Tensor 'unknown_514:0' shape=() dtype=resource>, <tf.Tensor 'unknown_515:0' shape=() dtype=resource>, <tf.Tensor 'unknown_516:0' shape=() dtype=resource>, <tf.Tensor 'unknown_517:0' shape=() dtype=resource>, <tf.Tensor 'unknown_518:0' shape=() dtype=resource>, <tf.Tensor 'unknown_519:0' shape=() dtype=resource>, <tf.Tensor 'unknown_520:0' shape=() dtype=resource>, <tf.Tensor 'unknown_521:0' shape=() dtype=resource>, <tf.Tensor 'unknown_522:0' shape=() dtype=resource>, <tf.Tensor 'unknown_523:0' shape=() dtype=resource>, <tf.Tensor 'unknown_524:0' shape=() dtype=resource>, <tf.Tensor 'unknown_525:0' shape=() dtype=resource>, <tf.Tensor 'unknown_526:0' shape=() dtype=resource>, <tf.Tensor 'unknown_527:0' shape=() dtype=resource>, <tf.Tensor 'unknown_528:0' shape=() dtype=resource>, <tf.Tensor 'unknown_529:0' shape=() dtype=resource>, <tf.Tensor 'unknown_530:0' shape=() dtype=resource>, <tf.Tensor 'unknown_531:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_532:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_533:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_534:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_535:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_536:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_537:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_538:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_539:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_540:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_541:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_542:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_543:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_544:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_545:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_546:0' shape=() dtype=resource>, <tf.Tensor 'unknown_547:0' shape=() dtype=resource>, <tf.Tensor 'unknown_548:0' shape=() dtype=resource>, <tf.Tensor 'unknown_549:0' shape=() dtype=resource>, <tf.Tensor 'unknown_550:0' shape=() dtype=resource>, <tf.Tensor 'unknown_551:0' shape=() dtype=resource>, <tf.Tensor 'unknown_552:0' shape=() dtype=resource>, <tf.Tensor 'unknown_553:0' shape=() dtype=resource>, <tf.Tensor 'unknown_554:0' shape=() dtype=resource>, <tf.Tensor 'unknown_555:0' shape=() dtype=resource>, <tf.Tensor 'unknown_556:0' shape=() dtype=resource>, <tf.Tensor 'unknown_557:0' shape=() dtype=resource>, <tf.Tensor 'unknown_558:0' shape=() dtype=resource>, <tf.Tensor 'unknown_559:0' shape=() dtype=resource>, <tf.Tensor 'unknown_560:0' shape=() dtype=resource>, <tf.Tensor 'unknown_561:0' shape=() dtype=resource>, <tf.Tensor 'unknown_562:0' shape=() dtype=resource>, <tf.Tensor 'unknown_563:0' shape=() dtype=resource>, <tf.Tensor 'unknown_564:0' shape=() dtype=resource>, <tf.Tensor 'unknown_565:0' shape=() dtype=resource>, <tf.Tensor 'unknown_566:0' shape=() dtype=resource>, <tf.Tensor 'unknown_567:0' shape=() dtype=resource>, <tf.Tensor 'unknown_568:0' shape=() dtype=resource>, <tf.Tensor 'unknown_569:0' shape=() dtype=resource>, <tf.Tensor 'unknown_570:0' shape=() dtype=resource>, <tf.Tensor 'unknown_571:0' shape=() dtype=resource>, <tf.Tensor 'unknown_572:0' shape=() dtype=resource>, <tf.Tensor 'unknown_573:0' shape=() dtype=resource>, <tf.Tensor 'unknown_574:0' shape=() dtype=resource>, <tf.Tensor 'unknown_575:0' shape=() dtype=resource>, <tf.Tensor 'unknown_576:0' shape=() dtype=resource>, <tf.Tensor 'unknown_577:0' shape=() dtype=resource>, <tf.Tensor 'unknown_578:0' shape=() dtype=resource>, <tf.Tensor 'unknown_579:0' shape=() dtype=resource>, <tf.Tensor 'unknown_580:0' shape=() dtype=resource>, <tf.Tensor 'unknown_581:0' shape=() dtype=resource>, <tf.Tensor 'unknown_582:0' shape=() dtype=resource>, <tf.Tensor 'unknown_583:0' shape=() dtype=resource>, <tf.Tensor 'unknown_584:0' shape=() dtype=resource>, <tf.Tensor 'unknown_585:0' shape=() dtype=resource>, <tf.Tensor 'unknown_586:0' shape=() dtype=resource>, <tf.Tensor 'unknown_587:0' shape=() dtype=resource>, <tf.Tensor 'unknown_588:0' shape=() dtype=resource>, <tf.Tensor 'unknown_589:0' shape=() dtype=resource>, <tf.Tensor 'unknown_590:0' shape=() dtype=resource>, <tf.Tensor 'unknown_591:0' shape=() dtype=resource>, <tf.Tensor 'unknown_592:0' shape=() dtype=resource>, <tf.Tensor 'unknown_593:0' shape=() dtype=resource>, <tf.Tensor 'unknown_594:0' shape=() dtype=resource>, <tf.Tensor 'unknown_595:0' shape=() dtype=resource>, <tf.Tensor 'unknown_596:0' shape=() dtype=resource>, <tf.Tensor 'unknown_597:0' shape=() dtype=resource>, <tf.Tensor 'unknown_598:0' shape=() dtype=resource>, <tf.Tensor 'unknown_599:0' shape=() dtype=resource>, <tf.Tensor 'unknown_600:0' shape=() dtype=resource>, <tf.Tensor 'unknown_601:0' shape=() dtype=resource>, <tf.Tensor 'unknown_602:0' shape=() dtype=resource>, <tf.Tensor 'unknown_603:0' shape=() dtype=resource>, <tf.Tensor 'unknown_604:0' shape=() dtype=resource>, <tf.Tensor 'unknown_605:0' shape=() dtype=resource>, <tf.Tensor 'unknown_606:0' shape=() dtype=resource>, <tf.Tensor 'unknown_607:0' shape=() dtype=resource>, <tf.Tensor 'unknown_608:0' shape=() dtype=resource>, <tf.Tensor 'unknown_609:0' shape=() dtype=resource>, <tf.Tensor 'unknown_610:0' shape=() dtype=resource>, <tf.Tensor 'unknown_611:0' shape=() dtype=resource>, <tf.Tensor 'unknown_612:0' shape=() dtype=resource>, <tf.Tensor 'unknown_613:0' shape=() dtype=resource>, <tf.Tensor 'unknown_614:0' shape=() dtype=resource>, <tf.Tensor 'unknown_615:0' shape=() dtype=resource>, <tf.Tensor 'unknown_616:0' shape=() dtype=resource>, <tf.Tensor 'unknown_617:0' shape=() dtype=resource>, <tf.Tensor 'unknown_618:0' shape=() dtype=resource>, <tf.Tensor 'unknown_619:0' shape=() dtype=resource>, <tf.Tensor 'unknown_620:0' shape=() dtype=resource>, <tf.Tensor 'unknown_621:0' shape=() dtype=resource>, <tf.Tensor 'unknown_622:0' shape=() dtype=resource>, <tf.Tensor 'unknown_623:0' shape=() dtype=resource>, <tf.Tensor 'unknown_624:0' shape=() dtype=resource>, <tf.Tensor 'unknown_625:0' shape=() dtype=resource>, <tf.Tensor 'unknown_626:0' shape=() dtype=resource>, <tf.Tensor 'unknown_627:0' shape=() dtype=resource>, <tf.Tensor 'unknown_628:0' shape=() dtype=resource>, <tf.Tensor 'unknown_629:0' shape=() dtype=resource>, <tf.Tensor 'unknown_630:0' shape=() dtype=resource>, <tf.Tensor 'unknown_631:0' shape=() dtype=resource>, <tf.Tensor 'unknown_632:0' shape=() dtype=resource>, <tf.Tensor 'unknown_633:0' shape=() dtype=resource>, <tf.Tensor 'unknown_634:0' shape=() dtype=resource>, <tf.Tensor 'unknown_635:0' shape=() dtype=resource>, <tf.Tensor 'unknown_636:0' shape=() dtype=resource>, <tf.Tensor 'unknown_637:0' shape=() dtype=resource>, <tf.Tensor 'unknown_638:0' shape=() dtype=resource>, <tf.Tensor 'unknown_639:0' shape=() dtype=resource>, <tf.Tensor 'unknown_640:0' shape=() dtype=resource>, <tf.Tensor 'unknown_641:0' shape=() dtype=resource>, <tf.Tensor 'unknown_642:0' shape=() dtype=resource>, <tf.Tensor 'unknown_643:0' shape=() dtype=resource>, <tf.Tensor 'unknown_644:0' shape=() dtype=resource>, <tf.Tensor 'unknown_645:0' shape=() dtype=resource>, <tf.Tensor 'unknown_646:0' shape=() dtype=resource>, <tf.Tensor 'unknown_647:0' shape=() dtype=resource>, <tf.Tensor 'unknown_648:0' shape=() dtype=resource>, <tf.Tensor 'unknown_649:0' shape=() dtype=resource>, <tf.Tensor 'unknown_650:0' shape=() dtype=resource>, <tf.Tensor 'unknown_651:0' shape=() dtype=resource>, <tf.Tensor 'unknown_652:0' shape=() dtype=resource>, <tf.Tensor 'unknown_653:0' shape=() dtype=resource>, <tf.Tensor 'unknown_654:0' shape=() dtype=resource>, <tf.Tensor 'unknown_655:0' shape=() dtype=resource>, <tf.Tensor 'unknown_656:0' shape=() dtype=resource>, <tf.Tensor 'unknown_657:0' shape=() dtype=resource>, <tf.Tensor 'unknown_658:0' shape=() dtype=resource>, <tf.Tensor 'unknown_659:0' shape=() dtype=resource>, <tf.Tensor 'unknown_660:0' shape=() dtype=resource>, <tf.Tensor 'unknown_661:0' shape=() dtype=resource>, <tf.Tensor 'unknown_662:0' shape=() dtype=resource>, <tf.Tensor 'unknown_663:0' shape=() dtype=resource>, <tf.Tensor 'unknown_664:0' shape=() dtype=resource>, <tf.Tensor 'unknown_665:0' shape=() dtype=resource>, <tf.Tensor 'unknown_666:0' shape=() dtype=resource>, <tf.Tensor 'unknown_667:0' shape=() dtype=resource>, <tf.Tensor 'unknown_668:0' shape=() dtype=resource>, <tf.Tensor 'unknown_669:0' shape=() dtype=resource>, <tf.Tensor 'unknown_670:0' shape=() dtype=resource>, <tf.Tensor 'unknown_671:0' shape=() dtype=resource>, <tf.Tensor 'unknown_672:0' shape=() dtype=resource>, <tf.Tensor 'unknown_673:0' shape=() dtype=resource>, <tf.Tensor 'unknown_674:0' shape=() dtype=resource>, <tf.Tensor 'unknown_675:0' shape=() dtype=resource>, <tf.Tensor 'unknown_676:0' shape=() dtype=resource>, <tf.Tensor 'unknown_677:0' shape=() dtype=resource>, <tf.Tensor 'unknown_678:0' shape=() dtype=resource>, <tf.Tensor 'unknown_679:0' shape=() dtype=resource>, <tf.Tensor 'unknown_680:0' shape=() dtype=resource>, <tf.Tensor 'unknown_681:0' shape=() dtype=resource>, <tf.Tensor 'unknown_682:0' shape=() dtype=resource>, <tf.Tensor 'unknown_683:0' shape=() dtype=resource>, <tf.Tensor 'unknown_684:0' shape=() dtype=resource>, <tf.Tensor 'unknown_685:0' shape=() dtype=resource>, <tf.Tensor 'unknown_686:0' shape=() dtype=resource>, <tf.Tensor 'unknown_687:0' shape=() dtype=resource>, <tf.Tensor 'unknown_688:0' shape=() dtype=resource>, <tf.Tensor 'unknown_689:0' shape=() dtype=resource>]\n"
          ]
        }
      ],
      "source": [
        "print(detection_model.signatures['serving_default'].inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spwWfepequdc",
        "outputId": "ab43a9ad-4966-40e2-b88f-76de96798c3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detection_anchor_indices': tf.float32,\n",
              " 'detection_boxes': tf.float32,\n",
              " 'detection_classes': tf.float32,\n",
              " 'detection_multiclass_scores': tf.float32,\n",
              " 'detection_scores': tf.float32,\n",
              " 'num_detections': tf.float32,\n",
              " 'raw_detection_boxes': tf.float32,\n",
              " 'raw_detection_scores': tf.float32}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "detection_model.signatures['serving_default'].output_dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_wO46B3qyNr",
        "outputId": "df366f7b-5201-4a09-8cb2-79e12e2d6f80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detection_anchor_indices': TensorShape([1, 100]),\n",
              " 'detection_boxes': TensorShape([1, 100, 4]),\n",
              " 'detection_classes': TensorShape([1, 100]),\n",
              " 'detection_multiclass_scores': TensorShape([1, 100, 1]),\n",
              " 'detection_scores': TensorShape([1, 100]),\n",
              " 'num_detections': TensorShape([1]),\n",
              " 'raw_detection_boxes': TensorShape([1, 49104, 4]),\n",
              " 'raw_detection_scores': TensorShape([1, 49104, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "detection_model.signatures['serving_default'].output_shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "tMotDfEyctPu"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "XoSpuPI7bs1x"
      },
      "outputs": [],
      "source": [
        "#recover our saved model\n",
        "pipeline_config = pipeline_file\n",
        "#generally you want to put the last ckpt from training in here\n",
        "model_dir = '/content/drive/MyDrive/SOCCER_Object_Detection/Barcelona'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "ckpt.restore(os.path.join('/content/drive/MyDrive/SOCCER_Object_Detection/Barcelona/checkpoint/ckpt-0'))\n",
        "\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "gg1Hwdu1dT5V"
      },
      "outputs": [],
      "source": [
        "#map labels for inference decoding\n",
        "label_map_path = configs['eval_input_config'].label_map_path\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6On9QiGdV80",
        "outputId": "ad21d752-b6eb-4c44-c5f0-7caff4a9f459"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-32332f83c0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mTEST_IMAGE_PATHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/SOCCER_Object_Detection/Frames/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_IMAGE_PATHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_into_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
          ]
        }
      ],
      "source": [
        "#run detector on test image\n",
        "#it takes a little longer on the first run and then runs at normal speed. \n",
        "import random\n",
        "\n",
        "TEST_IMAGE_PATHS = glob.glob('/content/drive/MyDrive/SOCCER_Object_Detection/Frames/*.jpg')\n",
        "image_path = random.choice(TEST_IMAGE_PATHS)\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(\n",
        "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'][0].numpy(),\n",
        "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.3,\n",
        "      agnostic_mode=False,\n",
        ")\n",
        "\n",
        "(im_width, im_height) = image_np.shape[:2]\n",
        "ymin = detections['detection_boxes'][0][0]*im_height\n",
        "xmin = detections['detection_boxes'][0][1]*im_width\n",
        "ymax = detections['detection_boxes'][0][2]*im_height\n",
        "xmax = detections['detection_boxes'][0][3]*im_width\n",
        "\n",
        "plt.figure(figsize=(12,16))\n",
        "plt.imshow(image_np_with_detections)\n",
        "\n",
        "if detections['detection_scores'][0][0]>= 0.4: \n",
        "   print (xmin,ymin)\n",
        "   print (xmax,ymax)\n",
        "   plt.imsave(\"/content/BARCA-PLAYER-IDENTIFICATION--1/predict\"+str(count)+\".jpg\", image_np_with_detections)\n",
        "   plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SOCCER_VIDEO_Barcelona _Object_detection.ipynb",
      "provenance": [],
      "mount_file_id": "1Lvw8PHoS6tU9yYKIbmSXBIkcpfixVY6h",
      "authorship_tag": "ABX9TyMC4HsdEm9pKYZpapReX0NE",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}